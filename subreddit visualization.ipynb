{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Reddit Data\n",
    "\n",
    "## TODO\n",
    "\n",
    "Identify subreddits with known inauthentic activity, assign unique color on map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adjustText\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.sparse as ss\n",
    "from os.path import isfile\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import bokeh\n",
    "from bokeh.palettes import plasma\n",
    "from bokeh.models.mappers import LinearColorMapper\n",
    "from bokeh.plotting import figure, show, output_notebook, output_file\n",
    "from bokeh.models import HoverTool, ColumnDataSource, value, CustomJS, DataRange1d\n",
    "from collections import OrderedDict\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from IPython.display import clear_output\n",
    "\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subreddit Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"data/subreddit_overlaps_BQ.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1_subreddit</th>\n",
       "      <th>t2_subreddit</th>\n",
       "      <th>NumOverlaps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RimWorld</td>\n",
       "      <td>archeage</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unitedkingdom</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>3282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trumpgret</td>\n",
       "      <td>dankchristianmemes</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>humor</td>\n",
       "      <td>childfree</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>customhearthstone</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46304397</th>\n",
       "      <td>Marijuana</td>\n",
       "      <td>justicedemocrats</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46304398</th>\n",
       "      <td>MaliciousCompliance</td>\n",
       "      <td>dankruto</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46304399</th>\n",
       "      <td>C25K</td>\n",
       "      <td>ProjectFi</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46304400</th>\n",
       "      <td>Embroidery</td>\n",
       "      <td>casualChildAbuse</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46304401</th>\n",
       "      <td>RecruitCS</td>\n",
       "      <td>atheism</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46304402 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 t1_subreddit        t2_subreddit  NumOverlaps\n",
       "0                    RimWorld            archeage           84\n",
       "1               unitedkingdom        pcmasterrace         3282\n",
       "2                   Trumpgret  dankchristianmemes          322\n",
       "3                       humor           childfree           54\n",
       "4           customhearthstone              Tinder          411\n",
       "...                       ...                 ...          ...\n",
       "46304397            Marijuana    justicedemocrats           18\n",
       "46304398  MaliciousCompliance            dankruto           18\n",
       "46304399                 C25K           ProjectFi           18\n",
       "46304400           Embroidery    casualChildAbuse           18\n",
       "46304401            RecruitCS             atheism           18\n",
       "\n",
       "[46304402 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumOverlaps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.630440e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.253839e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.023249e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.165000e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        NumOverlaps\n",
       "count  4.630440e+07\n",
       "mean   1.253839e+01\n",
       "std    1.023249e+02\n",
       "min    1.000000e+00\n",
       "25%    1.000000e+00\n",
       "50%    2.000000e+00\n",
       "75%    6.000000e+00\n",
       "max    4.165000e+04"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairwise commenter overlaps: 46304402\n",
      "t1_subreddit unique subreddits: 2029\n",
      "t2_subreddit unique subreddits: 131271\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of pairwise commenter overlaps: {}\".format(len(raw_data)))\n",
    "print(\"t1_subreddit unique subreddits: {}\".format(len(raw_data[\"t1_subreddit\"].unique())))\n",
    "print(\"t2_subreddit unique subreddits: {}\".format(len(raw_data[\"t2_subreddit\"].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rank the subreddits so that they are indexed in order of popularity. Popularity is defined by the total number of unique commenters in each subreddit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_popularity = raw_data.groupby('t2_subreddit')['NumOverlaps'].sum()\n",
    "subreddits = np.array(subreddit_popularity.sort_values(ascending=False).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AskReddit', 'pics', 'funny', 'todayilearned', 'gaming']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddits.tolist()[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot the data into a matrix such that rows and columns are both indexed by subreddits, and the entry at position (i,j) is the number of overlaps bwteen the ith and jth subreddits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create subreddit-to-integer-index map to convert the subreddit names in the table into numeric row and column indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_map = dict(np.vstack([subreddits, np.arange(subreddits.shape[0])]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = raw_data.NumOverlaps\n",
    "row_indices = raw_data.t2_subreddit.map(index_map)\n",
    "col_indices = raw_data.t1_subreddit.map(index_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a sparse matrix. This format requires us to specify triples of row, column, and value for each non-zero entry in the matrix. The COO matrix constructor accepts this as a triple of arrays: the first array is the values, the second and third are arrays of row and column indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = ss.coo_matrix((values, (row_indices,col_indices)),\n",
    "                              shape=(subreddits.shape[0], subreddits.shape[0]),\n",
    "                              dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131271, 131271)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_prob_matrix = count_matrix.tocsr()\n",
    "conditional_prob_matrix = normalize(conditional_prob_matrix, norm='l1', copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting subreddit vectors into a map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear dimensionality reduction down to 500 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_vectors = TruncatedSVD(n_components=500, random_state=1).fit_transform(conditional_prob_matrix)\n",
    "reduced_vectors = normalize(reduced_vectors, norm='l2', copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131271, 500)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlinear dimensionality reduction down to 2 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LargeVis(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, n_components=2, perplexity=30.0, gamma=5,\n",
    "                 layout_samples=None, n_neighbors=None, negative_samples=5,\n",
    "                 alpha=1.0, n_cores=4, knn_prop=3, trees=50):\n",
    "        self.n_components = n_components\n",
    "        self.perplexity = perplexity\n",
    "        self.layout_samples = layout_samples\n",
    "        self.alpha = alpha\n",
    "        self.n_cores = n_cores\n",
    "        self.knn_prop = knn_prop\n",
    "        self.negative_samples = negative_samples\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.gamma = gamma\n",
    "        self.trees = trees\n",
    "        if self.n_neighbors is None:\n",
    "            self.n_neighbors = int(self.perplexity * 3)\n",
    "\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        \n",
    "        if self.layout_samples is None:\n",
    "            layout_samples = X.shape[0] / 100.0\n",
    "        else:\n",
    "            layout_samples = self.layout_samples\n",
    "            \n",
    "        X = check_array(X, dtype=np.float64)\n",
    "        np.savetxt('/tmp/largevis_input', \n",
    "                   X, header='{} {}'.format(*X.shape), \n",
    "                   comments='')\n",
    "        subprocess.check_call(['/Users/cameronlaedtke/LargeVis-python3/Linux/LargeVis',\n",
    "                               '-input',  '/tmp/largevis_input',\n",
    "                               '-output', '/tmp/largevis_output',\n",
    "                               '-outdim',  str(self.n_components),\n",
    "                               '-perp',    str(self.perplexity),\n",
    "                               '-samples', str(layout_samples),\n",
    "                               '-gamma',   str(self.gamma),\n",
    "                               '-prop',    str(self.knn_prop),\n",
    "                               '-trees',   str(self.trees),\n",
    "                               '-neigh',   str(self.n_neighbors),\n",
    "                               '-alpha',   str(self.alpha),\n",
    "                               '-neg',     str(self.negative_samples),\n",
    "                               '-threads', str(self.n_cores)])\n",
    "        self.embedding_ = np.loadtxt('/tmp/largevis_output', skiprows=1)\n",
    "        return self.embedding_\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.fit_transform(X)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed_file = 'tsne_data/largevis_subreddit_map_low_perplexity.npy'\n",
    "# plot_file = 'viz/subreddit_interactive_map_low_perplexity.html'\n",
    "\n",
    "embed_file = 'tsne_data/largevis_subreddit_map.npy'\n",
    "plot_file = 'viz/subreddit_interactive_map.html'\n",
    "\n",
    "if isfile(embed_file):\n",
    "    subreddit_map = np.load(embed_file)\n",
    "else:\n",
    "    largevis = LargeVis(perplexity=20, n_cores=12)\n",
    "    subreddit_map = largevis.fit_transform(reduced_vectors[:10000])\n",
    "    np.save(embed_file, subreddit_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.508770</td>\n",
       "      <td>-0.510874</td>\n",
       "      <td>AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-6.329569</td>\n",
       "      <td>-0.267770</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.479487</td>\n",
       "      <td>-0.431000</td>\n",
       "      <td>funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.256063</td>\n",
       "      <td>-0.035419</td>\n",
       "      <td>todayilearned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.290978</td>\n",
       "      <td>14.978483</td>\n",
       "      <td>gaming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x          y      subreddit\n",
       "0 -6.508770  -0.510874      AskReddit\n",
       "1 -6.329569  -0.267770           pics\n",
       "2 -6.479487  -0.431000          funny\n",
       "3 -6.256063  -0.035419  todayilearned\n",
       "4 -5.290978  14.978483         gaming"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_map_df = pd.DataFrame(subreddit_map, columns=('x', 'y'))\n",
    "subreddit_map_df['subreddit'] = subreddits[:10000]\n",
    "subreddit_map_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = HDBSCAN(min_samples=5, min_cluster_size=20).fit(subreddit_map)\n",
    "cluster_ids = clusterer.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.508770</td>\n",
       "      <td>-0.510874</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-6.329569</td>\n",
       "      <td>-0.267770</td>\n",
       "      <td>pics</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.479487</td>\n",
       "      <td>-0.431000</td>\n",
       "      <td>funny</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.256063</td>\n",
       "      <td>-0.035419</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.290978</td>\n",
       "      <td>14.978483</td>\n",
       "      <td>gaming</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x          y      subreddit  cluster\n",
       "0 -6.508770  -0.510874      AskReddit       -1\n",
       "1 -6.329569  -0.267770           pics      136\n",
       "2 -6.479487  -0.431000          funny      136\n",
       "3 -6.256063  -0.035419  todayilearned      136\n",
       "4 -5.290978  14.978483         gaming       36"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_map_df['cluster'] = cluster_ids\n",
    "subreddit_map_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points assigned to a cluster: 8493\n",
      "number of clusters: 145\n",
      "silhouette score: 0.3514\n"
     ]
    }
   ],
   "source": [
    "n_cluster_points = len(subreddit_map_df[subreddit_map_df.cluster != -1])\n",
    "n_clusters = subreddit_map_df[\"cluster\"].max()\n",
    "score = silhouette_score(subreddit_map, cluster_ids)\n",
    "print(\"points assigned to a cluster: {}\".format(n_cluster_points))\n",
    "print(\"number of clusters: {}\".format(n_clusters))\n",
    "print(\"silhouette score: {:.4f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_palette(size, palette_func):\n",
    "    if size < 256:\n",
    "        return palette_func(size)\n",
    "    p = palette_func(256)\n",
    "    out = []\n",
    "    for i in range(size):\n",
    "        idx = int(i * 256.0 / size)\n",
    "        out.append(p[idx])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Construct a color palette and map clusters to colors\n",
    "if cluster_ids.max() > 255:\n",
    "    palette = ['#777777'] + big_palette(size=cluster_ids.max(), palette_func=plasma)\n",
    "else:\n",
    "    palette = ['#777777'] + list(plasma(cluster_ids.max()))\n",
    "\n",
    "colormap = LinearColorMapper(palette=palette, low=-1, high=cluster_ids.max())\n",
    "color_dict = {'field': 'cluster', 'transform': colormap}\n",
    "\n",
    "# Set fill alpha globally\n",
    "subreddit_map_df['fill_alpha'] = np.exp((subreddit_map.min() - subreddit_map.max()) / 5.0) + 0.05\n",
    "\n",
    "# Build a column data source\n",
    "plot_data = ColumnDataSource(data=subreddit_map_df)\n",
    "\n",
    "# Create the figure and add tools\n",
    "fig = figure(\n",
    "    title='A Map of Subreddits',\n",
    "    plot_width = 1150,\n",
    "    plot_height = 1150,\n",
    "    tools= ('pan, wheel_zoom, box_zoom,''box_select, reset'),\n",
    "    active_scroll=u'wheel_zoom',\n",
    ")\n",
    "\n",
    "fig.add_tools(HoverTool(tooltips = OrderedDict([('subreddit', '@subreddit'), \n",
    "                                                ('cluster', '@cluster')])))\n",
    "\n",
    "# draw the subreddits as circles on the plot\n",
    "fig.circle(\n",
    "    u'x', u'y', \n",
    "    source = plot_data,\n",
    "    fill_color = color_dict, \n",
    "    line_color = None, \n",
    "    fill_alpha = 'fill_alpha',\n",
    "    size = 10, \n",
    "    hover_line_color = u'black'\n",
    ")\n",
    "\n",
    "# Custom callback for alpha adjustment\n",
    "jscode=\"\"\"\n",
    "    var data = source.data;\n",
    "    var start = cb_obj.start;\n",
    "    var end = cb_obj.end;\n",
    "    var alpha = data['fill_alpha'];\n",
    "    var i = 0;\n",
    "    for (i = 0; i < alpha.length; i++) {\n",
    "         alpha[i] = Math.exp((start - end) / 5.0) + 0.05;\n",
    "    }\n",
    "    source.change.emit();\n",
    "\"\"\"\n",
    "\n",
    "callback = CustomJS(args=dict(source=plot_data), code=jscode)\n",
    "\n",
    "fig.x_range.js_on_change(\"start\", callback)\n",
    "fig.x_range.js_on_change(\"end\", callback)\n",
    "\n",
    "# configure visual elements of the plot\n",
    "fig.title.text_font_size = value('18pt')\n",
    "fig.title.align = 'center'\n",
    "fig.xaxis.visible = False\n",
    "fig.yaxis.visible = False\n",
    "fig.grid.grid_line_color = None\n",
    "fig.outline_line_color = '#222222'\n",
    "\n",
    "# display the figure\n",
    "output_file(plot_file)\n",
    "show(fig);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_bounds(dataframe, subreddit):\n",
    "    # Find the cluster the subreddit belongs to\n",
    "    cluster = dataframe.cluster[dataframe.subreddit == subreddit].values[0]\n",
    "    if cluster == -1:\n",
    "        print('This subreddit was lost as noise and not in any cluster')\n",
    "        \n",
    "    # Extract the dubset of the dataframe that is the cluster\n",
    "    sub_dataframe = dataframe[dataframe.cluster == cluster]\n",
    "    \n",
    "    x_min = sub_dataframe.x.min()\n",
    "    x_max = sub_dataframe.x.max()\n",
    "    x_padding = (x_max - x_min) * 0.5\n",
    "    x_min -= x_padding\n",
    "    x_max += x_padding\n",
    "    \n",
    "    y_min = sub_dataframe.y.min()\n",
    "    y_max = sub_dataframe.y.max()\n",
    "    y_padding = (y_max - y_min) * 0.5\n",
    "    y_min -= y_padding\n",
    "    y_max += y_padding\n",
    "\n",
    "    return x_min, x_max, y_min, y_max\n",
    "\n",
    "\n",
    "def data_in_bounds(dataframe, bounds):\n",
    "    return dataframe[\n",
    "        (dataframe.x > bounds[0]) &\n",
    "        (dataframe.x < bounds[1]) &\n",
    "        (dataframe.y > bounds[2]) &\n",
    "        (dataframe.y < bounds[3])\n",
    "    ]\n",
    "\n",
    "\n",
    "def plot_cluster(dataframe, subreddit, n_labels=50, fontsize=9, dpi=100):\n",
    "    # Build a color map to match the Bokeh plot\n",
    "    colormap = dict(zip(\n",
    "        np.unique(dataframe.cluster),\n",
    "        ['#777777'] + sns.color_palette('plasma', dataframe.cluster.max() + 1).as_hex()\n",
    "    ))\n",
    "    subregion_defined = True\n",
    "    \n",
    "    # Figure and gridspec to layout axes\n",
    "    fig = plt.figure(figsize=(16,10), dpi=dpi)\n",
    "    gs = GridSpec(3, 3)\n",
    "    \n",
    "    # First axes, spanning most of the figure\n",
    "    # Contains just the points in a region \n",
    "    # around the points in the cluster\n",
    "    ax1 = plt.subplot(gs[:,:2])\n",
    "    try:\n",
    "        bounds = cluster_bounds(dataframe, subreddit)\n",
    "    except IndexError:\n",
    "        ax1.text(0.5, 0.5, 'Subreddit {} not found!'.format(subreddit), \n",
    "                 horizontalalignment='center', verticalalignment='center',\n",
    "                 transform=ax1.transAxes, fontsize=18)\n",
    "        subregion_defined = False\n",
    "    \n",
    "    if subregion_defined:\n",
    "        to_plot = data_in_bounds(dataframe, bounds)\n",
    "        ax1.scatter(to_plot.x, to_plot.y, c=to_plot.cluster.map(colormap), s=30, alpha=0.5)\n",
    "    \n",
    "        # We want to add text labels. We subsample up to 50 labels\n",
    "        # And then use adjustText to get them non-overlapping\n",
    "        text_elements = []\n",
    "        for row in to_plot.sample(n=min(len(to_plot), n_labels), random_state=0).values:\n",
    "            if row[2] != subreddit:\n",
    "                text_elements.append(ax1.text(row[0], row[1], row[2], alpha=0.5, fontsize=fontsize))\n",
    "        row = to_plot[to_plot.subreddit == subreddit].values[0]\n",
    "        text_elements.append(ax1.text(row[0], row[1], row[2], \n",
    "                                      color='g',\n",
    "                                      alpha=0.5, fontsize=11))\n",
    "        adjustText.adjust_text(text_elements, ax=ax1, lim=100,\n",
    "                               force_text=0.1, force_points=0.1,\n",
    "                               arrowprops=dict(arrowstyle=\"-\", color='k', lw=0.5))\n",
    "    \n",
    "    ax1.xaxis.set_ticklabels([])\n",
    "    ax1.yaxis.set_ticklabels([])\n",
    "\n",
    "    # Second axes, center right of the figure\n",
    "    # Plots all the data and a rectangle\n",
    "    # Showing the area selected out\n",
    "    ax2 = plt.subplot(gs[1,2])\n",
    "    ax2.scatter(dataframe.x, dataframe.y, s=20,\n",
    "                c=dataframe.cluster.map(colormap), alpha=0.05)\n",
    "    \n",
    "    if subregion_defined:\n",
    "        ax2.add_patch(Rectangle(xy=(bounds[0], bounds[2]),\n",
    "                                    width=(bounds[1] - bounds[0]),\n",
    "                                    height=(bounds[3] - bounds[2]),\n",
    "                                    edgecolor='k', facecolor='none', lw=1))\n",
    "    ax2.xaxis.set_ticklabels([])\n",
    "    ax2.yaxis.set_ticklabels([])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if subregion_defined:\n",
    "        # Now we make use of the power of matplotlib transforms\n",
    "        # to draw line from the subselected rectangle in axes2\n",
    "        # all the way to the bounds of axes1\n",
    "        trans_figure = fig.transFigure.inverted()\n",
    "\n",
    "        ax1_coord = trans_figure.transform(ax1.transAxes.transform((1,0)))\n",
    "        ax2_coord = trans_figure.transform(ax2.transData.transform((bounds[1],bounds[2])))\n",
    "        connector1 = Line2D((ax1_coord[0],ax2_coord[0]),(ax1_coord[1],ax2_coord[1]),\n",
    "                              transform=fig.transFigure, lw=1, color='k')\n",
    "        ax1_coord = trans_figure.transform(ax1.transAxes.transform((1,1)))\n",
    "        ax2_coord = trans_figure.transform(ax2.transData.transform((bounds[1],bounds[3])))\n",
    "        connector2 = Line2D((ax1_coord[0],ax2_coord[0]),(ax1_coord[1],ax2_coord[1]),\n",
    "                              transform=fig.transFigure, lw=1, color='k')\n",
    "\n",
    "        fig.lines = [connector1, connector2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(subreddit_map_df, 'StopVoterSuppression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(subreddit_map_df, 'marxism_101', n_labels=100, fontsize=7, dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(subreddit_map_df, 'scottishpolitics', n_labels=100, fontsize=7, dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(subreddit_map_df, 'USHistory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(subreddit_map_df, 'Menaregood', n_labels=100, fontsize=7, dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(subreddit_map_df, 'tuesday', n_labels=150, fontsize=7, dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_cluster(subreddit_map_df, 'Le_Pen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(subreddit_map_df, 'bidenbro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(subreddit_map_df, 'exmuslim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(subreddit_map_df, 'MuslimLounge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(subreddit_map_df, 'geopolitics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(subreddit_map_df, 'france', n_labels=200, fontsize=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(subreddit_map_df, 'China')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(subreddit_map_df, 'taiwan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_cluster(subreddit_map_df, 'cybersecurity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(subreddit_map_df, 'ipad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(subreddit_map_df, 'JoeRogan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(subreddit_map_df, 'minnesota')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_cluster(subreddit_map_df, 'vexillology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(subreddit_map_df, 'environment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_cluster(subreddit_map_df, 'elonmusk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(subreddit_map_df, 'trees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact_manual, fixed, Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(plot_cluster, \n",
    "                dataframe=fixed(subreddit_map_df), \n",
    "                subreddit=Text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherent_clusters = np.argsort(clusterer.cluster_persistence_)[-10:][::-1]\n",
    "coherence = np.sort(clusterer.cluster_persistence_)[-10:][::-1]\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.bar(np.arange(10), coherence)\n",
    "plt.gca().set_xticks(np.arange(10))\n",
    "plt.gca().set_xticklabels(coherent_clusters)\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Coherence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_by_id(dataframe, cluster_id):\n",
    "    subreddits_in_cluster = np.array(dataframe.subreddit[cluster_ids == cluster_id])\n",
    "    plot_cluster(dataframe, subreddits_in_cluster[0])\n",
    "    plt.gcf().text(0.5, 0.98, 'Cluster {}'.format(cluster_id), ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_by_id(subreddit_map_df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_by_id(subreddit_map_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_by_id(subreddit_map_df, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_by_id(subreddit_map_df, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_by_id(subreddit_map_df, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_by_id(subreddit_map_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_by_id(subreddit_map_df, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_by_id(subreddit_map_df, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_by_id(subreddit_map_df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_by_id(subreddit_map_df, 37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python37764bitae051cd17d8f4a168e3a898050509ec5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
