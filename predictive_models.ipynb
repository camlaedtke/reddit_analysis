{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kyPQ3c-yVIp"
   },
   "source": [
    "# Models\n",
    "\n",
    "Trying out word embeddings, and comparing them to one-hot embeddings for visualization and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25869,
     "status": "ok",
     "timestamp": 1606966948015,
     "user": {
      "displayName": "Cameron Laedtke",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjdHvTpQBUhnTxCbHhpkxuEaFh6HcxY6QIb9OVX=s64",
      "userId": "09150441049660052621"
     },
     "user_tz": 360
    },
    "id": "L-CCHeDox0Sr",
    "outputId": "df8a2c1f-0f5f-4fea-fd37-637a4258bfe0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from gensim.models.fasttext import FastText\n",
    "from gensim.parsing.preprocessing import remove_stopwords, preprocess_string\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gf7tIdc34_wI"
   },
   "source": [
    "# Import Preprocessed Dataset\n",
    "\n",
    "Data is generated from PREPROCESSING.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 2967,
     "status": "ok",
     "timestamp": 1606966953091,
     "user": {
      "displayName": "Cameron Laedtke",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjdHvTpQBUhnTxCbHhpkxuEaFh6HcxY6QIb9OVX=s64",
      "userId": "09150441049660052621"
     },
     "user_tz": 360
    },
    "id": "9pHupmafyBbT",
    "outputId": "067fa9f0-49ee-406e-9ae3-e8b704e25791"
   },
   "outputs": [],
   "source": [
    "comments = pd.read_pickle(\"reddit_data/DATASET.pkl\")\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUVOLVfn_2F7"
   },
   "source": [
    "# Embed Words Into Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 629,
     "status": "ok",
     "timestamp": 1606966968825,
     "user": {
      "displayName": "Cameron Laedtke",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjdHvTpQBUhnTxCbHhpkxuEaFh6HcxY6QIb9OVX=s64",
      "userId": "09150441049660052621"
     },
     "user_tz": 360
    },
    "id": "Lz5v3KG0ykmS"
   },
   "outputs": [],
   "source": [
    "def generate_FastText_embeddings(df, vector_size=100, window=3, min_count=1):\n",
    "    rows = np.array([preprocess_string(row['body_text']) for i, row in df.iterrows()])\n",
    "    # if you want to remove stopwords automatically, you can try the following:\n",
    "    # rows = np.array([preprocess_string(remove_stopwords(row['Text'])) for row in df])\n",
    "    # print(rows[0])  \n",
    "\n",
    "    # train the model\n",
    "    model = FastText(size=vector_size, window=window, min_count=min_count)\n",
    "    model.build_vocab(rows)\n",
    "    model.train(sentences=rows, total_examples=len(rows), epochs=10) \n",
    "\n",
    "    # average the vectors to get a vector that represents a whole comment\n",
    "    vecs = np.zeros((len(rows), vector_size))\n",
    "\n",
    "    for i in range(len(rows)):\n",
    "        # some are empty\n",
    "        if (rows[i] != []):\n",
    "            vecs[i, :] = sum([model.wv.get_vector(word) for word in rows[i]]) / len(rows[i])\n",
    "\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1606966969856,
     "user": {
      "displayName": "Cameron Laedtke",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjdHvTpQBUhnTxCbHhpkxuEaFh6HcxY6QIb9OVX=s64",
      "userId": "09150441049660052621"
     },
     "user_tz": 360
    },
    "id": "tDCvd6vMygKG"
   },
   "outputs": [],
   "source": [
    "def generate_onehot_embeddings(df, max_features=2**12):\n",
    "    vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "    vecs = vectorizer.fit_transform(df['body_text'].values)\n",
    "    return vecs.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06nCRNhmN2e0"
   },
   "source": [
    "Experiment with different vector sizes. So far I've tried 100 and 16. I think 100 performs better. Also, if the vector size is small enough you can feed it directly into t-SNE instead of doing PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSu_U5RIyT4j"
   },
   "outputs": [],
   "source": [
    "X_fasttext = generate_FastText_embeddings(df=comments, vector_size=50, window=3, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H0sMVIcc0t7A"
   },
   "outputs": [],
   "source": [
    "X_onehot = generate_onehot_embeddings(df=comments, max_features=2**12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6sYKU793KNs"
   },
   "source": [
    "# Compare Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26e-WSgh1IhY"
   },
   "source": [
    "For plotting, use PCA to get both datasets down to reasonable number of dimensions, then use t-SNE.\n",
    "\n",
    "### Note for our report\n",
    "\n",
    "The plots below should be able to give us a lot of material to include in the report, since we get a birdseye view of the two different subreddits. Try finding distinct clusters of points in the t-SNE plot, and hover over the comments to see what the similarities are.\n",
    "\n",
    "An important thing to look for in the plots are the distinct clusters of points that are all the same color. From what I've seen so far, these represent comments that have certain words or small phrases that are unique to the \"liberal\" or \"conservative\" subreddit. For example, I noticed there are a bunch of comments in r/Conservative that mention \"sjw\" (social justice warrior), so you might find all those comments clumped together. \n",
    "\n",
    "These distinct words or phrases are probably a big part of what any machine learning model will use for predictions, so that is something to keep in mind when analyzing model performance as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ux__oVmq9wHd"
   },
   "source": [
    "### Note on t-SNE\n",
    "\n",
    "If you're not familiar with t-SNE, check out this link\n",
    "\n",
    "\n",
    "https://distill.pub/2016/misread-tsne/\n",
    "\n",
    "\n",
    "\n",
    "From my experience, the only parameter that really matters is \"perplexity\". I have no idea what it means, but on big datasets like ours it generally has the effect of changing the \"clumpyness\" of the datapoints. Lower values of perplexity tend to produce larger \"clumps\" of points, whereas higher perplexity gives lots of smaller clumps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FvSgTz371gX6"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=20) \n",
    "\n",
    "pca_result_onehot = pca.fit_transform(X_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xNLk58PB156S"
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(\n",
    "    verbose=0, \n",
    "    n_components=2,\n",
    "    perplexity=30, # good values are 10-50. 30 is default.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmxry6kqQavc"
   },
   "source": [
    "#### The following two code blocks might not work in Collab. And if they do it'll take like an hour. It works on my local machine though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Be1uf8Q183y"
   },
   "outputs": [],
   "source": [
    "X_fasttext_2D = tsne.fit_transform(X_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I_37HqyX2DwP"
   },
   "outputs": [],
   "source": [
    "X_onehot_2D = tsne.fit_transform(pca_result_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BM-0ixrq2LGz"
   },
   "outputs": [],
   "source": [
    "def format_df_for_plotting(df):\n",
    "    df_formatted = df.copy(deep=True)\n",
    "    df_formatted.body_text = df_formatted.body_text.str.wrap(30)\n",
    "    df_formatted.body_text = df_formatted.body_text.apply(lambda x: x.replace('\\n', '<br>'))\n",
    "    return df_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UnfBXRdZ2Pep"
   },
   "outputs": [],
   "source": [
    "comments_formatted = format_df_for_plotting(df=comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3k_C8SL2Qjw"
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "    data=go.Scattergl(\n",
    "        name=\"\",\n",
    "        x=X_fasttext_2D[:,0],\n",
    "        y=X_fasttext_2D[:,1],\n",
    "        # z=X_con_embedded[:,2], \n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=4,\n",
    "            opacity=0.7,\n",
    "            color = comments_formatted[\"label\"],\n",
    "            #colorscale=\"jet\"\n",
    "        ),\n",
    "        text=comments_formatted['body_text'],\n",
    "        hovertemplate = \"</br> %{text}\",\n",
    "    )\n",
    ") \n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(text='t-SNE r/Conservative and r/politics Comments', x=0.5, font_size=30),\n",
    "    template=\"plotly_white\",\n",
    "    height=800,\n",
    "    hoverlabel=dict(\n",
    "        bgcolor=\"white\",\n",
    "        font_size=24,\n",
    "    ),\n",
    "    xaxis=dict(visible=False),\n",
    "    yaxis=dict(visible=False),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TcmiDery2pBQ"
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "    data=go.Scattergl( \n",
    "        name=\"\",\n",
    "        x=X_onehot_2D[:,0],\n",
    "        y=X_onehot_2D[:,1],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=4, \n",
    "            opacity=0.7,\n",
    "            color = comments_formatted[\"label\"],\n",
    "            #colorscale=\"jet\"\n",
    "        ),\n",
    "        text=comments_formatted['body_text'],\n",
    "        hovertemplate = \"</br> %{text}\",\n",
    "    ),\n",
    ") \n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(text='t-SNE r/Conservative and r/politics Comments', x=0.5, font_size=30),\n",
    "    template=\"plotly_white\",\n",
    "    height=800,\n",
    "    hoverlabel=dict(\n",
    "        bgcolor=\"white\",\n",
    "        font_size=24,\n",
    "    ),\n",
    "    xaxis=dict(visible=False),\n",
    "    yaxis=dict(visible=False),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlP3ZhR63IdV"
   },
   "source": [
    "# Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJQmkmiI3QZs"
   },
   "outputs": [],
   "source": [
    "labels = np.array(comments[\"label\"].tolist())\n",
    "\n",
    "X_ft_train, X_ft_valid, y_ft_train, y_ft_valid = train_test_split(X_fasttext, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "X_oh_train, X_oh_valid, y_oh_train, y_oh_valid = train_test_split(X_onehot, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CGNhNWVz3tn3"
   },
   "outputs": [],
   "source": [
    "fasttext_models = {\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    #\"Decision Tree\": DecisionTreeClassifier(),\n",
    "    #\"Bagging Ensemble\": BaggingClassifier(),\n",
    "    #\"KNN\": KNeighborsClassifier(),\n",
    "    #\"SVM\": SVC(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lezr-FpR3z7j"
   },
   "outputs": [],
   "source": [
    "onehot_models = {\n",
    "    \"Multinomial Naive Bayes\": MultinomialNB(),\n",
    "    #\"Decision Tree\": DecisionTreeClassifier(),\n",
    "    #\"Bagging Ensemble\": BaggingClassifier(),\n",
    "    #\"KNN\": KNeighborsClassifier(), \n",
    "    #\"SVM\": SVC(), takes at least 2 hours.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kbq_VtjM4K4t"
   },
   "source": [
    "### Model Results Using FastText Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 899267,
     "status": "ok",
     "timestamp": 1606958647952,
     "user": {
      "displayName": "Cameron Laedtke",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjdHvTpQBUhnTxCbHhpkxuEaFh6HcxY6QIb9OVX=s64",
      "userId": "09150441049660052621"
     },
     "user_tz": 360
    },
    "id": "wGK75ghu4E0Y",
    "outputId": "1c8b9eff-f337-4090-9d8b-008c7cd3c7a8"
   },
   "outputs": [],
   "source": [
    "for key in fasttext_models:\n",
    "    print(key)\n",
    "    model = fasttext_models[key]\n",
    "    model.fit(X_ft_train, y_ft_train)\n",
    "    y_pred = model.predict(X_ft_valid)\n",
    "    print('Accuracy score: {:.4f}'.format(accuracy_score(y_ft_valid, y_pred)))\n",
    "    print('Precision score: {:.4f}'.format(precision_score(y_ft_valid, y_pred)))\n",
    "    print('Recall score: {:.4f}'.format(recall_score(y_ft_valid, y_pred)))\n",
    "    print('F1 score: {:.4f} \\n'.format(f1_score(y_ft_valid, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5dZJUaJ4SwS"
   },
   "source": [
    "### Model Results Using Tf-Idf OneHot Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFXbLES-4Yxp",
    "outputId": "40706775-e7ce-446c-d8d8-4186483da762"
   },
   "outputs": [],
   "source": [
    "for key in onehot_models:\n",
    "    print(key)\n",
    "    model = onehot_models[key]\n",
    "    model.fit(X_oh_train, y_oh_train)\n",
    "    y_pred = model.predict(X_oh_valid)\n",
    "    print('Accuracy score: {:.4f}'.format(accuracy_score(y_oh_valid, y_pred)))\n",
    "    print('Precision score: {:.4f}'.format(precision_score(y_oh_valid, y_pred)))\n",
    "    print('Recall score: {:.4f}'.format(recall_score(y_oh_valid, y_pred)))\n",
    "    print('F1 score: {:.4f} \\n'.format(f1_score(y_oh_valid, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oX5WpaA-Gq9e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN/zg9qxLFVH1QbvzhOAplr",
   "collapsed_sections": [],
   "name": "MODELS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
